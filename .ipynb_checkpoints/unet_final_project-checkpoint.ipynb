{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "828d2fadb694c84f41867478a9608b822949f6a7"
   },
   "source": [
    "# **Contents**\n",
    "1. [Overview](#1.-Overview)\n",
    "1. [Data preparation](#2.-Data-preparation)\n",
    "1. [Segmentation training](#3.-Segmentation-training)\n",
    "1. [Results](#4.-Results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "516c9b53d192813594987edec5c0552c4449607c"
   },
   "source": [
    "# 1. Overview\n",
    "This notebook follows the work of [Kevin Mader](https://www.kaggle.com/kmader/training-u-net-on-tb-images-to-segment-lungs/notebook) for lung segmentation. Our motivation is to learn abnormalities on the lung on chest X-ray, training a UNet to segment the scans and finally building a scoring system for discriminating severity of pneumonia.\n",
    "\n",
    "Medical Image Segmentation is the process of automatic detection of boundaries within images. In this exercise, we train and coompare two convolutional neural network with [U-Net](https://arxiv.org/abs/1505.04597) architecture and latest [ladder U-Net](https://arxiv.org/abs/1810.07810) architecture, which training strategy relies on the strong use of data augmentation to improve the efficiency of available annotated samples.\n",
    "\n",
    "The training is done with two chest x-rays datasets: [Montgomery County and Shenzhen Hospital](https://ceb.nlm.nih.gov/repositories/tuberculosis-chest-x-ray-image-data-sets/). The Montgomery County dataset includes manually segmented lung masks, whereas Shenzhen Hospital dataset was manually segmented by [Stirenko et al](https://arxiv.org/abs/1803.01199). The lung segmentation masks were dilated to load lung boundary information within the training net and the images were resized to 512x512 pixels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "2392d90df7ff92794b4d5ef9c47c102b289fd724"
   },
   "source": [
    "# 2. Data preparation\n",
    "Prepare the input segmentation directory structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "763240ce0dbdfb26510ded9b55b5bc94d400f74e"
   },
   "outputs": [],
   "source": [
    "!mkdir ../input/segmentation\n",
    "!mkdir ../input/segmentation/test\n",
    "!mkdir ../input/segmentation/train\n",
    "!mkdir ../input/segmentation/train/augmentation\n",
    "!mkdir ../input/segmentation/train/image\n",
    "!mkdir ../input/segmentation/train/mask\n",
    "!mkdir ../input/segmentation/train/dilate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "e222153d13b6602792f447ed86401f3ee5d4965b"
   },
   "source": [
    "Import required Python libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "cb2b30651cf57582f7715325ea9519f04f4407d4"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from keras.models import *\n",
    "from keras.layers import *\n",
    "from keras.optimizers import *\n",
    "from keras import backend as keras\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
    "\n",
    "from glob import glob\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "2f6aa09deb74f25f9937d16ef32ddc32a22d780c"
   },
   "source": [
    "Define appropriate constants for directory paths and training parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "5307ff8180fe09ccb769e1e9809e33061451c5e1"
   },
   "outputs": [],
   "source": [
    "INPUT_DIR = os.path.join(\"..\", \"input\")\n",
    "\n",
    "SEGMENTATION_DIR = os.path.join(INPUT_DIR, \"segmentation\")\n",
    "SEGMENTATION_TEST_DIR = os.path.join(SEGMENTATION_DIR, \"test\")\n",
    "SEGMENTATION_TRAIN_DIR = os.path.join(SEGMENTATION_DIR, \"train\")\n",
    "SEGMENTATION_AUG_DIR = os.path.join(SEGMENTATION_TRAIN_DIR, \"augmentation\")\n",
    "SEGMENTATION_IMAGE_DIR = os.path.join(SEGMENTATION_TRAIN_DIR, \"image\")\n",
    "SEGMENTATION_MASK_DIR = os.path.join(SEGMENTATION_TRAIN_DIR, \"mask\")\n",
    "SEGMENTATION_DILATE_DIR = os.path.join(SEGMENTATION_TRAIN_DIR, \"dilate\")\n",
    "SEGMENTATION_SOURCE_DIR = os.path.join(INPUT_DIR, \\\n",
    "                                       \"pulmonary-chest-xray-abnormalities\")\n",
    "\n",
    "SHENZHEN_TRAIN_DIR = os.path.join(SEGMENTATION_SOURCE_DIR, \"ChinaSet_AllFiles\", \\\n",
    "                                  \"ChinaSet_AllFiles\")\n",
    "SHENZHEN_IMAGE_DIR = os.path.join(SHENZHEN_TRAIN_DIR, \"CXR_png\")\n",
    "SHENZHEN_MASK_DIR = os.path.join(INPUT_DIR, \"shcxr-lung-mask\", \"mask\", \"mask\")\n",
    "\n",
    "MONTGOMERY_TRAIN_DIR = os.path.join(SEGMENTATION_SOURCE_DIR, \\\n",
    "                                    \"Montgomery\", \"MontgomerySet\")\n",
    "MONTGOMERY_IMAGE_DIR = os.path.join(MONTGOMERY_TRAIN_DIR, \"CXR_png\")\n",
    "MONTGOMERY_LEFT_MASK_DIR = os.path.join(MONTGOMERY_TRAIN_DIR, \\\n",
    "                                        \"ManualMask\", \"leftMask\")\n",
    "MONTGOMERY_RIGHT_MASK_DIR = os.path.join(MONTGOMERY_TRAIN_DIR, \\\n",
    "                                         \"ManualMask\", \"rightMask\")\n",
    "\n",
    "DILATE_KERNEL = np.ones((15, 15), np.uint8)\n",
    "\n",
    "BATCH_SIZE=2\n",
    "\n",
    "#Prod\n",
    "EPOCHS=56\n",
    "\n",
    "#Desv\n",
    "#EPOCHS=16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "8a8adbf02b8a5c0b014b4e833e48d089e4f89035"
   },
   "source": [
    "1. Combine left and right lung segmentation masks of Montgomery chest x-rays\n",
    "1. Resize images to 512x512 pixels\n",
    "1. Dilate masks to gain more information on the edge of lungs\n",
    "1. Split images into training and test datasets\n",
    "1. Write images to /segmentation directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "b8e995d39dc50ae09aaca9fca60d5f01a4afa493"
   },
   "outputs": [],
   "source": [
    "montgomery_left_mask_dir = glob(os.path.join(MONTGOMERY_LEFT_MASK_DIR, '*.png'))\n",
    "montgomery_test = montgomery_left_mask_dir[0:50]\n",
    "montgomery_train= montgomery_left_mask_dir[50:]\n",
    "\n",
    "for left_image_file in tqdm(montgomery_left_mask_dir):\n",
    "    base_file = os.path.basename(left_image_file)\n",
    "    image_file = os.path.join(MONTGOMERY_IMAGE_DIR, base_file)\n",
    "    right_image_file = os.path.join(MONTGOMERY_RIGHT_MASK_DIR, base_file)\n",
    "\n",
    "    image = cv2.imread(image_file)\n",
    "    left_mask = cv2.imread(left_image_file, cv2.IMREAD_GRAYSCALE)\n",
    "    right_mask = cv2.imread(right_image_file, cv2.IMREAD_GRAYSCALE)\n",
    "    \n",
    "    image = cv2.resize(image, (512, 512))\n",
    "    left_mask = cv2.resize(left_mask, (512, 512))\n",
    "    right_mask = cv2.resize(right_mask, (512, 512))\n",
    "    \n",
    "    mask = np.maximum(left_mask, right_mask)\n",
    "    mask_dilate = cv2.dilate(mask, DILATE_KERNEL, iterations=1)\n",
    "    \n",
    "    if (left_image_file in montgomery_train):\n",
    "        cv2.imwrite(os.path.join(SEGMENTATION_IMAGE_DIR, base_file), \\\n",
    "                    image)\n",
    "        cv2.imwrite(os.path.join(SEGMENTATION_MASK_DIR, base_file), \\\n",
    "                    mask)\n",
    "        cv2.imwrite(os.path.join(SEGMENTATION_DILATE_DIR, base_file), \\\n",
    "                    mask_dilate)\n",
    "    else:\n",
    "        filename, fileext = os.path.splitext(base_file)\n",
    "        cv2.imwrite(os.path.join(SEGMENTATION_TEST_DIR, base_file), \\\n",
    "                    image)\n",
    "        cv2.imwrite(os.path.join(SEGMENTATION_TEST_DIR, \\\n",
    "                                 \"%s_mask%s\" % (filename, fileext)), mask)\n",
    "        cv2.imwrite(os.path.join(SEGMENTATION_TEST_DIR, \\\n",
    "                                 \"%s_dilate%s\" % (filename, fileext)), mask_dilate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "d6f4b42dcde137249d107e754efa7c25087224d1"
   },
   "source": [
    "Define some useful functions to display images with segmentation as overlays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "46e63227a43918c9189e192402be274f5e1e4466"
   },
   "outputs": [],
   "source": [
    "def add_colored_dilate(image, mask_image, dilate_image):\n",
    "    mask_image_gray = cv2.cvtColor(mask_image, cv2.COLOR_BGR2GRAY)\n",
    "    dilate_image_gray = cv2.cvtColor(dilate_image, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    mask = cv2.bitwise_and(mask_image, mask_image, mask=mask_image_gray)\n",
    "    dilate = cv2.bitwise_and(dilate_image, dilate_image, mask=dilate_image_gray)\n",
    "    \n",
    "    mask_coord = np.where(mask!=[0,0,0])\n",
    "    dilate_coord = np.where(dilate!=[0,0,0])\n",
    "\n",
    "    mask[mask_coord[0],mask_coord[1],:]=[255,0,0]\n",
    "    dilate[dilate_coord[0],dilate_coord[1],:] = [0,0,255]\n",
    "\n",
    "    ret = cv2.addWeighted(image, 0.7, dilate, 0.3, 0)\n",
    "    ret = cv2.addWeighted(ret, 0.7, mask, 0.3, 0)\n",
    "\n",
    "    return ret\n",
    "\n",
    "def add_colored_mask(image, mask_image):\n",
    "    mask_image_gray = cv2.cvtColor(mask_image, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    mask = cv2.bitwise_and(mask_image, mask_image, mask=mask_image_gray)\n",
    "    \n",
    "    mask_coord = np.where(mask!=[0,0,0])\n",
    "\n",
    "    mask[mask_coord[0],mask_coord[1],:]=[255,0,0]\n",
    "\n",
    "    ret = cv2.addWeighted(image, 0.7, mask, 0.3, 0)\n",
    "\n",
    "    return ret\n",
    "\n",
    "def diff_mask(ref_image, mask_image):\n",
    "    mask_image_gray = cv2.cvtColor(mask_image, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    mask = cv2.bitwise_and(mask_image, mask_image, mask=mask_image_gray)\n",
    "    \n",
    "    mask_coord = np.where(mask!=[0,0,0])\n",
    "\n",
    "    mask[mask_coord[0],mask_coord[1],:]=[255,0,0]\n",
    "\n",
    "    ret = cv2.addWeighted(ref_image, 0.7, mask, 0.3, 0)\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "a5eb09219a9cb07e2bd6bc855304ad5fb805415f"
   },
   "source": [
    "Show some Montgomery chest x-rays and its lung segmentation masks from training and test dataset to verify the procedure above. In merged image it is possible to see the difference between the dilated mask in blue and the original mask in red."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": false,
    "_kg_hide-output": false,
    "_uuid": "51da123d5e86d7dce7dfb126d76d83cf90dd0154"
   },
   "outputs": [],
   "source": [
    "base_file = os.path.basename(montgomery_train[0])\n",
    "\n",
    "image_file = os.path.join(SEGMENTATION_IMAGE_DIR, base_file)\n",
    "mask_image_file = os.path.join(SEGMENTATION_MASK_DIR, base_file)\n",
    "dilate_image_file = os.path.join(SEGMENTATION_DILATE_DIR, base_file)\n",
    "\n",
    "image = cv2.imread(image_file)\n",
    "mask_image = cv2.imread(mask_image_file)\n",
    "dilate_image = cv2.imread(dilate_image_file)\n",
    "merged_image = add_colored_dilate(image, mask_image, dilate_image)\n",
    "                          \n",
    "fig, axs = plt.subplots(2, 4, figsize=(15, 8))\n",
    "\n",
    "axs[0, 0].set_title(\"X-Ray\")\n",
    "axs[0, 0].imshow(image)\n",
    "\n",
    "axs[0, 1].set_title(\"Mask\")\n",
    "axs[0, 1].imshow(mask_image)\n",
    "\n",
    "axs[0, 2].set_title(\"Dilate\")\n",
    "axs[0, 2].imshow(dilate_image)\n",
    "\n",
    "axs[0, 3].set_title(\"Merged\")\n",
    "axs[0, 3].imshow(merged_image)\n",
    "\n",
    "base_file = os.path.basename(montgomery_test[0])\n",
    "filename, fileext = os.path.splitext(base_file)\n",
    "image_file = os.path.join(SEGMENTATION_TEST_DIR, base_file)\n",
    "mask_image_file = os.path.join(SEGMENTATION_TEST_DIR, \\\n",
    "                               \"%s_mask%s\" % (filename, fileext))\n",
    "dilate_image_file = os.path.join(SEGMENTATION_TEST_DIR, \\\n",
    "                                 \"%s_dilate%s\" % (filename, fileext))\n",
    "\n",
    "image = cv2.imread(image_file)\n",
    "mask_image = cv2.imread(mask_image_file)\n",
    "dilate_image = cv2.imread(dilate_image_file)\n",
    "merged_image = add_colored_dilate(image, mask_image, dilate_image)\n",
    "\n",
    "axs[1, 0].set_title(\"X-Ray\")\n",
    "axs[1, 0].imshow(image)\n",
    "\n",
    "axs[1, 1].set_title(\"Mask\")\n",
    "axs[1, 1].imshow(mask_image)\n",
    "\n",
    "axs[1, 2].set_title(\"Dilate\")\n",
    "axs[1, 2].imshow(dilate_image)\n",
    "\n",
    "axs[1, 3].set_title(\"Merged\")\n",
    "axs[1, 3].imshow(merged_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "961855a0ef2989b675ad037a1c674acf53701396"
   },
   "source": [
    "1. Resize Shenzhen Hospital chest x-ray images to 512x512 pixels\n",
    "1. Dilate masks to gain more information on the edge of lungs\n",
    "1. Split images into training and test datasets\n",
    "1. Write images to /segmentation directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "de6eed98634dca524e5f326b8635cced94b0ce9b"
   },
   "outputs": [],
   "source": [
    "shenzhen_mask_dir = glob(os.path.join(SHENZHEN_MASK_DIR, '*.png'))\n",
    "shenzhen_test = shenzhen_mask_dir[0:50]\n",
    "shenzhen_train= shenzhen_mask_dir[50:]\n",
    "\n",
    "for mask_file in tqdm(shenzhen_mask_dir):\n",
    "    base_file = os.path.basename(mask_file).replace(\"_mask\", \"\")\n",
    "    image_file = os.path.join(SHENZHEN_IMAGE_DIR, base_file)\n",
    "\n",
    "    image = cv2.imread(image_file)\n",
    "    mask = cv2.imread(mask_file, cv2.IMREAD_GRAYSCALE)\n",
    "        \n",
    "    image = cv2.resize(image, (512, 512))\n",
    "    mask = cv2.resize(mask, (512, 512))\n",
    "    mask_dilate = cv2.dilate(mask, DILATE_KERNEL, iterations=1)\n",
    "    \n",
    "    if (mask_file in shenzhen_train):\n",
    "        cv2.imwrite(os.path.join(SEGMENTATION_IMAGE_DIR, base_file), \\\n",
    "                    image)\n",
    "        cv2.imwrite(os.path.join(SEGMENTATION_MASK_DIR, base_file), \\\n",
    "                    mask)\n",
    "        cv2.imwrite(os.path.join(SEGMENTATION_DILATE_DIR, base_file), \\\n",
    "                    mask_dilate)\n",
    "    else:\n",
    "        filename, fileext = os.path.splitext(base_file)\n",
    "\n",
    "        cv2.imwrite(os.path.join(SEGMENTATION_TEST_DIR, base_file), \\\n",
    "                    image)\n",
    "        cv2.imwrite(os.path.join(SEGMENTATION_TEST_DIR, \\\n",
    "                                 \"%s_mask%s\" % (filename, fileext)), mask)\n",
    "        cv2.imwrite(os.path.join(SEGMENTATION_TEST_DIR, \\\n",
    "                                 \"%s_dilate%s\" % (filename, fileext)), mask_dilate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "9e6e9dbb064305877847351015aba026582f7bb3"
   },
   "source": [
    "Show some Shenzhen Hospital chest x-rays and its lung segmentation masks from training and test dataset to verify the procedure above. In merged image it is possible to see the difference between the dilated mask in blue and the original mask in red."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "e9923cd36413cc086db684d3a076cbba9b479778"
   },
   "outputs": [],
   "source": [
    "base_file = os.path.basename(shenzhen_train[0].replace(\"_mask\", \"\"))\n",
    "\n",
    "image_file = os.path.join(SEGMENTATION_IMAGE_DIR, base_file)\n",
    "mask_image_file = os.path.join(SEGMENTATION_MASK_DIR, base_file)\n",
    "dilate_image_file = os.path.join(SEGMENTATION_DILATE_DIR, base_file)\n",
    "\n",
    "image = cv2.imread(image_file)\n",
    "mask_image = cv2.imread(mask_image_file)\n",
    "dilate_image = cv2.imread(dilate_image_file)\n",
    "merged_image = add_colored_dilate(image, mask_image, dilate_image)\n",
    "                          \n",
    "fig, axs = plt.subplots(2, 4, figsize=(15, 8))\n",
    "\n",
    "axs[0, 0].set_title(\"X-Ray\")\n",
    "axs[0, 0].imshow(image)\n",
    "\n",
    "axs[0, 1].set_title(\"Mask\")\n",
    "axs[0, 1].imshow(mask_image)\n",
    "\n",
    "axs[0, 2].set_title(\"Dilate\")\n",
    "axs[0, 2].imshow(dilate_image)\n",
    "\n",
    "axs[0, 3].set_title(\"Merged\")\n",
    "axs[0, 3].imshow(merged_image)\n",
    "\n",
    "base_file = os.path.basename(shenzhen_test[0].replace(\"_mask\", \"\"))\n",
    "image_file = os.path.join(SEGMENTATION_TEST_DIR, base_file)\n",
    "filename, fileext = os.path.splitext(base_file)\n",
    "mask_image_file = os.path.join(SEGMENTATION_TEST_DIR, \\\n",
    "                               \"%s_mask%s\" % (filename, fileext))\n",
    "\n",
    "filename, fileext = os.path.splitext(base_file)\n",
    "image_file = os.path.join(SEGMENTATION_TEST_DIR, base_file)\n",
    "mask_image_file = os.path.join(SEGMENTATION_TEST_DIR, \\\n",
    "                               \"%s_mask%s\" % (filename, fileext))\n",
    "dilate_image_file = os.path.join(SEGMENTATION_TEST_DIR, \\\n",
    "                                 \"%s_dilate%s\" % (filename, fileext))\n",
    "\n",
    "image = cv2.imread(image_file)\n",
    "mask_image = cv2.imread(mask_image_file)\n",
    "dilate_image = cv2.imread(dilate_image_file)\n",
    "merged_image = add_colored_dilate(image, mask_image, dilate_image)\n",
    "\n",
    "axs[1, 0].set_title(\"X-Ray\")\n",
    "axs[1, 0].imshow(image)\n",
    "\n",
    "axs[1, 1].set_title(\"Mask\")\n",
    "axs[1, 1].imshow(mask_image)\n",
    "\n",
    "axs[1, 2].set_title(\"Dilate\")\n",
    "axs[1, 2].imshow(dilate_image)\n",
    "\n",
    "axs[1, 3].set_title(\"Merged\")\n",
    "axs[1, 3].imshow(merged_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "67e2abed6ba57198cd442763925af44b493569ec"
   },
   "source": [
    "Print the count of images and segmentation lung masks available to test and train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "e5381719ef7e49e6823c1a9417e7eff7cfb1572e",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train_files = glob(os.path.join(SEGMENTATION_IMAGE_DIR, \"*.png\"))\n",
    "test_files = glob(os.path.join(SEGMENTATION_TEST_DIR, \"*.png\"))\n",
    "mask_files = glob(os.path.join(SEGMENTATION_MASK_DIR, \"*.png\"))\n",
    "dilate_files = glob(os.path.join(SEGMENTATION_DILATE_DIR, \"*.png\"))\n",
    "\n",
    "(len(train_files), \\\n",
    " len(test_files), \\\n",
    " len(mask_files), \\\n",
    " len(dilate_files))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "774eec88428a8d1899247401acfef369e20abd2e"
   },
   "source": [
    "# 3. Segmentation training\n",
    "\n",
    "References: https://github.com/zhixuhao/unet/, https://github.com/jocicmarko/ultrasound-nerve-segmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "ab2175b11034175361ed8595ef8715afd76fd04a"
   },
   "source": [
    "Data augmentation helper function for training the net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "2e51bb0ff0d463ff5fc26af0d7bc0f3df745bdaa"
   },
   "outputs": [],
   "source": [
    "# From: https://github.com/zhixuhao/unet/blob/master/data.py\n",
    "def train_generator(batch_size, train_path, image_folder, mask_folder, aug_dict,\n",
    "        image_color_mode=\"grayscale\",\n",
    "        mask_color_mode=\"grayscale\",\n",
    "        image_save_prefix=\"image\",\n",
    "        mask_save_prefix=\"mask\",\n",
    "        save_to_dir=None,\n",
    "        target_size=(256,256),\n",
    "        seed=1):\n",
    "    '''\n",
    "    can generate image and mask at the same time use the same seed for\n",
    "    image_datagen and mask_datagen to ensure the transformation for image\n",
    "    and mask is the same if you want to visualize the results of generator,\n",
    "    set save_to_dir = \"your path\"\n",
    "    '''\n",
    "    image_datagen = ImageDataGenerator(**aug_dict)\n",
    "    mask_datagen = ImageDataGenerator(**aug_dict)\n",
    "    \n",
    "    image_generator = image_datagen.flow_from_directory(\n",
    "        train_path,\n",
    "        classes = [image_folder],\n",
    "        class_mode = None,\n",
    "        color_mode = image_color_mode,\n",
    "        target_size = target_size,\n",
    "        batch_size = batch_size,\n",
    "        save_to_dir = save_to_dir,\n",
    "        save_prefix  = image_save_prefix,\n",
    "        seed = seed)\n",
    "\n",
    "    mask_generator = mask_datagen.flow_from_directory(\n",
    "        train_path,\n",
    "        classes = [mask_folder],\n",
    "        class_mode = None,\n",
    "        color_mode = mask_color_mode,\n",
    "        target_size = target_size,\n",
    "        batch_size = batch_size,\n",
    "        save_to_dir = save_to_dir,\n",
    "        save_prefix  = mask_save_prefix,\n",
    "        seed = seed)\n",
    "\n",
    "    train_gen = zip(image_generator, mask_generator)\n",
    "    \n",
    "    for (img, mask) in train_gen:\n",
    "        img, mask = adjust_data(img, mask)\n",
    "        yield (img,mask)\n",
    "\n",
    "def adjust_data(img,mask):\n",
    "    img = img / 255\n",
    "    mask = mask / 255\n",
    "    mask[mask > 0.5] = 1\n",
    "    mask[mask <= 0.5] = 0\n",
    "    \n",
    "    return (img, mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "11ad24573000715e344f314f9766867d8b228d45"
   },
   "source": [
    "### U-net architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "fd23bd3ff7c4ef8186043cfcc1a161b7b90ae893"
   },
   "outputs": [],
   "source": [
    "# # From: https://github.com/jocicmarko/ultrasound-nerve-segmentation/blob/master/train.py\n",
    "# def dice_coef(y_true, y_pred):\n",
    "#     y_true_f = keras.flatten(y_true)\n",
    "#     y_pred_f = keras.flatten(y_pred)\n",
    "#     intersection = keras.sum(y_true_f * y_pred_f)\n",
    "#     return (2. * intersection + 1) / (keras.sum(y_true_f) + keras.sum(y_pred_f) + 1)\n",
    "\n",
    "# def dice_coef_loss(y_true, y_pred):\n",
    "#     return -dice_coef(y_true, y_pred)\n",
    "\n",
    "# def unet(input_size=(256,256,1)):\n",
    "#     inputs = Input(input_size)\n",
    "    \n",
    "#     conv1 = Conv2D(32, (3, 3), activation='relu', padding='same')(inputs)\n",
    "#     conv1 = Conv2D(32, (3, 3), activation='relu', padding='same')(conv1)\n",
    "#     pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "\n",
    "#     conv2 = Conv2D(64, (3, 3), activation='relu', padding='same')(pool1)\n",
    "#     conv2 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv2)\n",
    "#     pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "\n",
    "#     conv3 = Conv2D(128, (3, 3), activation='relu', padding='same')(pool2)\n",
    "#     conv3 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv3)\n",
    "#     pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "\n",
    "#     conv4 = Conv2D(256, (3, 3), activation='relu', padding='same')(pool3)\n",
    "#     conv4 = Conv2D(256, (3, 3), activation='relu', padding='same')(conv4)\n",
    "#     pool4 = MaxPooling2D(pool_size=(2, 2))(conv4)\n",
    "\n",
    "#     conv5 = Conv2D(512, (3, 3), activation='relu', padding='same')(pool4)\n",
    "#     conv5 = Conv2D(512, (3, 3), activation='relu', padding='same')(conv5)\n",
    "\n",
    "#     up6 = concatenate([Conv2DTranspose(256, (2, 2), strides=(2, 2), padding='same')(conv5), conv4], axis=3)\n",
    "#     conv6 = Conv2D(256, (3, 3), activation='relu', padding='same')(up6)\n",
    "#     conv6 = Conv2D(256, (3, 3), activation='relu', padding='same')(conv6)\n",
    "\n",
    "#     up7 = concatenate([Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(conv6), conv3], axis=3)\n",
    "#     conv7 = Conv2D(128, (3, 3), activation='relu', padding='same')(up7)\n",
    "#     conv7 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv7)\n",
    "\n",
    "#     up8 = concatenate([Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(conv7), conv2], axis=3)\n",
    "#     conv8 = Conv2D(64, (3, 3), activation='relu', padding='same')(up8)\n",
    "#     conv8 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv8)\n",
    "\n",
    "#     up9 = concatenate([Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same')(conv8), conv1], axis=3)\n",
    "#     conv9 = Conv2D(32, (3, 3), activation='relu', padding='same')(up9)\n",
    "#     conv9 = Conv2D(32, (3, 3), activation='relu', padding='same')(conv9)\n",
    "\n",
    "#     conv10 = Conv2D(1, (1, 1), activation='sigmoid')(conv9)\n",
    "\n",
    "#     return Model(inputs=[inputs], outputs=[conv10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ladder Unet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_coef(y_true, y_pred):\n",
    "    y_true_f = keras.flatten(y_true)\n",
    "    y_pred_f = keras.flatten(y_pred)\n",
    "    intersection = keras.sum(y_true_f * y_pred_f)\n",
    "    return (2. * intersection + 1) / (keras.sum(y_true_f) + keras.sum(y_pred_f) + 1)\n",
    "\n",
    "def dice_coef_loss(y_true, y_pred):\n",
    "    return -dice_coef(y_true, y_pred)\n",
    "\n",
    "def cbr(x, out_layer, kernel, stride, dilation):\n",
    "    x = Conv2D(out_layer, kernel_size=kernel, dilation_rate=dilation, strides=stride, padding=\"same\")(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "    return x\n",
    "\n",
    "def se_block(x_in, layer_n):\n",
    "    x = GlobalAveragePooling2D()(x_in)\n",
    "    x = Dense(layer_n//8, activation=\"relu\")(x)\n",
    "    x = Dense(layer_n, activation=\"sigmoid\")(x)\n",
    "    x_out=Multiply()([x_in, x])\n",
    "    return x_out\n",
    "\n",
    "def resblock(x_in, layer_n, kernel, dilation, use_se=True):\n",
    "    x = cbr(x_in, layer_n, kernel, 1, dilation)\n",
    "    x = cbr(x, layer_n, kernel, 1, dilation)\n",
    "    if use_se:\n",
    "        x = se_block(x, layer_n)\n",
    "    x = Add()([x_in, x])\n",
    "    return x  \n",
    "\n",
    "def UUnet(input_shape=(256,256,1)):\n",
    "    layer_n = 64\n",
    "    kernel_size = 7\n",
    "    depth = 2\n",
    "\n",
    "    input_layer = Input(input_shape)    \n",
    "    input_layer_1 = AveragePooling2D(5)(input_layer)\n",
    "    input_layer_2 = AveragePooling2D(25)(input_layer)\n",
    "    \n",
    "    ##########################\n",
    "    ### First U-Net: Big-U ###\n",
    "    ##########################\n",
    "    \n",
    "    ########## Encoder 1\n",
    "    x = cbr(input_layer, layer_n, kernel_size, 1, 1)#1000\n",
    "    for i in range(depth):\n",
    "        x = resblock(x, layer_n, kernel_size, 1)\n",
    "    out_0 = x\n",
    "\n",
    "    x = cbr(x, layer_n*2, kernel_size, 5, 1)\n",
    "    for i in range(depth):\n",
    "        x = resblock(x, layer_n*2, kernel_size, 1)\n",
    "    out_1 = x\n",
    "\n",
    "    x = Concatenate()([x, input_layer_1])    \n",
    "    x = cbr(x, layer_n*3, kernel_size, 5, 1)\n",
    "    for i in range(depth):\n",
    "        x = resblock(x, layer_n*3, kernel_size, 1)\n",
    "    out_2 = x\n",
    "\n",
    "    x = Concatenate()([x, input_layer_2])    \n",
    "    x = cbr(x, layer_n*4, kernel_size, 5, 1)\n",
    "    for i in range(depth):\n",
    "        x = resblock(x, layer_n*4, kernel_size, 1)\n",
    "    \n",
    "    ########### Decoder 1\n",
    "    x = UpSampling2D(5)(x)\n",
    "    x = Concatenate()([x, out_2])\n",
    "    x = cbr(x, layer_n*3, kernel_size, 1, 1)\n",
    "\n",
    "    x = UpSampling2D(5)(x)\n",
    "    x = Concatenate()([x, out_1])\n",
    "    x = cbr(x, layer_n*2, kernel_size, 1, 1)\n",
    "\n",
    "    x = UpSampling2D(5)(x)\n",
    "    x = Concatenate()([x, out_0])\n",
    "    x = cbr(x, layer_n, kernel_size, 1, 1)   \n",
    "    \n",
    "    #############################\n",
    "    ### Second U-Net: Small-U ###\n",
    "    #############################\n",
    "    \n",
    "    ########## Encoder 2\n",
    "    #x = cbr(input_layer, layer_n, kernel_size, 1, 1)#1000\n",
    "    for i in range(depth):\n",
    "        x = resblock(x, layer_n, kernel_size, 1)\n",
    "    out_0 = x\n",
    "\n",
    "    x = cbr(x, layer_n*2, kernel_size, 5, 1)\n",
    "    for i in range(depth):\n",
    "        x = resblock(x, layer_n*2, kernel_size, 1)\n",
    "    out_1 = x\n",
    "\n",
    "    x = Concatenate()([x, input_layer_1])    \n",
    "    x = cbr(x, layer_n*3, kernel_size, 5, 1)\n",
    "    for i in range(depth):\n",
    "        x = resblock(x, layer_n*3, kernel_size, 1)\n",
    "    \n",
    "    ########### Decoder 2\n",
    "    x = UpSampling2D(5)(x)\n",
    "    x = Concatenate()([x, out_1])\n",
    "    x = cbr(x, layer_n*2, kernel_size, 1, 1)\n",
    "\n",
    "    x = UpSampling2D(5)(x)\n",
    "    x = Concatenate()([x, out_0])\n",
    "    x = cbr(x, layer_n, kernel_size, 1, 1) \n",
    "    \n",
    "    ###############################\n",
    "    ### Third U-Net: Smallest-U ###\n",
    "    ###############################\n",
    "    \n",
    "    ########## Encoder 2\n",
    "    #x = cbr(input_layer, layer_n, kernel_size, 1, 1)#1000\n",
    "    for i in range(depth):\n",
    "        x = resblock(x, layer_n, kernel_size, 1)\n",
    "    out_0 = x\n",
    "    \n",
    "    x = cbr(x, layer_n*2, kernel_size, 5, 1)\n",
    "    for i in range(depth):\n",
    "        x = resblock(x, layer_n*2, kernel_size, 1)\n",
    "    \n",
    "    ########### Decoder 2\n",
    "    x = UpSampling2D(5)(x)\n",
    "    x = Concatenate()([x, out_0])\n",
    "    x = cbr(x, layer_n, kernel_size, 1, 1)\n",
    "    \n",
    "    #classifier\n",
    "    x = Conv2D(11, kernel_size=kernel_size, strides=1, padding=\"same\")(x)\n",
    "    out = Activation(\"sigmoid\")(x)\n",
    "    \n",
    "    model = Model(input_layer, out)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "a5af02b028aec42c9b1e9f9312114febe0df602c"
   },
   "source": [
    "Helper functions to load test chest x-ray images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "00c16a2cd8fe3b47cddb7c4a7c1de31b5bae481c"
   },
   "outputs": [],
   "source": [
    "# From: https://github.com/zhixuhao/unet/blob/master/data.py\n",
    "def test_load_image(test_file, target_size=(256,256)):\n",
    "    img = cv2.imread(test_file, cv2.IMREAD_GRAYSCALE)\n",
    "    img = img / 255\n",
    "    img = cv2.resize(img, target_size)\n",
    "    img = np.reshape(img, img.shape + (1,))\n",
    "    img = np.reshape(img,(1,) + img.shape)\n",
    "    return img\n",
    "\n",
    "def test_generator(test_files, target_size=(256,256)):\n",
    "    for test_file in test_files:\n",
    "        yield test_load_image(test_file, target_size)\n",
    "        \n",
    "def save_result(save_path, npyfile, test_files):\n",
    "    for i, item in enumerate(npyfile):\n",
    "        result_file = test_files[i]\n",
    "        img = (item[:, :, 0] * 255.).astype(np.uint8)\n",
    "\n",
    "        filename, fileext = os.path.splitext(os.path.basename(result_file))\n",
    "\n",
    "        result_file = os.path.join(save_path, \"%s_predict%s\" % (filename, fileext))\n",
    "\n",
    "        cv2.imwrite(result_file, img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "c92b6dc486eefe890feec5fbd760cb766a3612f1"
   },
   "source": [
    "Select test and validation files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "09df4552b2a1c6935849214f4f439d2c581d8c16"
   },
   "outputs": [],
   "source": [
    "def add_suffix(base_file, suffix):\n",
    "    filename, fileext = os.path.splitext(base_file)\n",
    "    return \"%s_%s%s\" % (filename, suffix, fileext)\n",
    "\n",
    "test_files = [test_file for test_file in glob(os.path.join(SEGMENTATION_TEST_DIR, \"*.png\")) \\\n",
    "              if (\"_mask\" not in test_file \\\n",
    "                  and \"_dilate\" not in test_file \\\n",
    "                  and \"_predict\" not in test_file)]\n",
    "\n",
    "validation_data = (test_load_image(test_files[0], target_size=(512, 512)),\n",
    "                    test_load_image(add_suffix(test_files[0], \"dilate\"), target_size=(512, 512)))\n",
    "\n",
    "len(test_files), len(validation_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "f48364da322a5fd84178cac099510598e8c67f77"
   },
   "source": [
    "Prepare the U-Net model and train the model. It will take a while..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "9893f1eedda1d1fe36cfd042cc28144dd9d6b1f0",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train_generator_args = dict(rotation_range=0.2,\n",
    "                            width_shift_range=0.05,\n",
    "                            height_shift_range=0.05,\n",
    "                            shear_range=0.05,\n",
    "                            zoom_range=0.05,\n",
    "                            horizontal_flip=True,\n",
    "                            fill_mode='nearest')\n",
    "\n",
    "train_gen = train_generator(BATCH_SIZE,\n",
    "                            SEGMENTATION_TRAIN_DIR,\n",
    "                            'image',\n",
    "                            'dilate', \n",
    "                            train_generator_args,\n",
    "                            target_size=(512,512),\n",
    "                            save_to_dir=os.path.abspath(SEGMENTATION_AUG_DIR))\n",
    "\n",
    "model = unet(input_size=(512,512,1))\n",
    "model.compile(optimizer=Adam(lr=1e-5), loss=dice_coef_loss, \\\n",
    "                  metrics=[dice_coef, 'binary_accuracy'])\n",
    "model.summary()\n",
    "\n",
    "model_checkpoint = ModelCheckpoint('unet_lung_seg.hdf5', \n",
    "                                   monitor='loss', \n",
    "                                   verbose=1, \n",
    "                                   save_best_only=True)\n",
    "\n",
    "history = model.fit_generator(train_gen,\n",
    "                              steps_per_epoch=len(train_files) / BATCH_SIZE, \n",
    "                              epochs=EPOCHS, \n",
    "                              callbacks=[model_checkpoint],\n",
    "                              validation_data = validation_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "7fa6d4810998c47cca1d54005c5beb873cf3da8a"
   },
   "source": [
    "Show some results from model fitting history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "925c24f71ba1c8e3697312ff7315e5e9f8059a0b"
   },
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2, figsize = (15, 4))\n",
    "\n",
    "training_loss = history.history['loss']\n",
    "validation_loss = history.history['val_loss']\n",
    "\n",
    "training_accuracy = history.history['binary_accuracy']\n",
    "validation_accuracy = history.history['val_binary_accuracy']\n",
    "\n",
    "epoch_count = range(1, len(training_loss) + 1)\n",
    "\n",
    "axs[0].plot(epoch_count, training_loss, 'r--')\n",
    "axs[0].plot(epoch_count, validation_loss, 'b-')\n",
    "axs[0].legend(['Training Loss', 'Validation Loss'])\n",
    "\n",
    "axs[1].plot(epoch_count, training_accuracy, 'r--')\n",
    "axs[1].plot(epoch_count, validation_accuracy, 'b-')\n",
    "axs[1].legend(['Training Accuracy', 'Validation Accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "7ac5b6dbe1dd70125529ffe46d748ddc2c4cc2a3"
   },
   "source": [
    "Make lung segmentation predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "15ad649aa0d5e94f42a78b58c8d58cd96d82a42d"
   },
   "outputs": [],
   "source": [
    "test_gen = test_generator(test_files, target_size=(512,512))\n",
    "results = model.predict_generator(test_gen, len(test_files), verbose=1)\n",
    "save_result(SEGMENTATION_TEST_DIR, results, test_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "067ce01e33264729319d4c3105e99e30e5a19163"
   },
   "source": [
    "# 4. Results\n",
    "\n",
    "Below, we see some results from our work, presented as Predicted, Gold Standard (manually segmented) and the difference between segmentations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "3b1f04bd591e2dcfa01bfc239a52d574a75ca42b"
   },
   "outputs": [],
   "source": [
    "image = cv2.imread(\"../input/segmentation/test/CHNCXR_0003_0.png\")\n",
    "predict_image = cv2.imread(\"../input/segmentation/test/CHNCXR_0003_0_predict.png\")\n",
    "mask_image = cv2.imread(\"../input/segmentation/test/CHNCXR_0003_0_dilate.png\")\n",
    "\n",
    "fig, axs = plt.subplots(4, 3, figsize=(16, 16))\n",
    "\n",
    "axs[0, 0].set_title(\"Predicted\")\n",
    "axs[0, 0].imshow(add_colored_mask(image, predict_image))\n",
    "axs[0, 1].set_title(\"Gold Std.\")\n",
    "axs[0, 1].imshow(add_colored_mask(image, mask_image))\n",
    "axs[0, 2].set_title(\"Diff.\")\n",
    "axs[0, 2].imshow(diff_mask(mask_image, predict_image))\n",
    "\n",
    "image = cv2.imread(\"../input/segmentation/test/MCUCXR_0003_0.png\")\n",
    "predict_image = cv2.imread(\"../input/segmentation/test/MCUCXR_0003_0_predict.png\")\n",
    "mask_image = cv2.imread(\"../input/segmentation/test/MCUCXR_0003_0_dilate.png\")\n",
    "\n",
    "axs[1, 0].set_title(\"Predicted\")\n",
    "axs[1, 0].imshow(add_colored_mask(image, predict_image))\n",
    "axs[1, 1].set_title(\"Gold Std.\")\n",
    "axs[1, 1].imshow(add_colored_mask(image, mask_image))\n",
    "axs[1, 2].set_title(\"Diff.\")\n",
    "axs[1, 2].imshow(diff_mask(mask_image, predict_image))\n",
    "\n",
    "image = cv2.imread(\"../input/segmentation/test/CHNCXR_0020_0.png\")\n",
    "predict_image = cv2.imread(\"../input/segmentation/test/CHNCXR_0020_0_predict.png\")\n",
    "mask_image = cv2.imread(\"../input/segmentation/test/CHNCXR_0020_0_dilate.png\")\n",
    "\n",
    "axs[2, 0].set_title(\"Predicted\")\n",
    "axs[2, 0].imshow(add_colored_mask(image, predict_image))\n",
    "axs[2, 1].set_title(\"Gold Std.\")\n",
    "axs[2, 1].imshow(add_colored_mask(image, mask_image))\n",
    "axs[2, 2].set_title(\"Diff.\")\n",
    "axs[2, 2].imshow(diff_mask(mask_image, predict_image))\n",
    "\n",
    "image = cv2.imread(\"../input/segmentation/test/MCUCXR_0016_0.png\")\n",
    "predict_image = cv2.imread(\"../input/segmentation/test/MCUCXR_0016_0_predict.png\")\n",
    "mask_image = cv2.imread(\"../input/segmentation/test/MCUCXR_0016_0_dilate.png\")\n",
    "\n",
    "axs[3, 0].set_title(\"Predicted\")\n",
    "axs[3, 0].imshow(add_colored_mask(image, predict_image))\n",
    "axs[3, 1].set_title(\"Gold Std.\")\n",
    "axs[3, 1].imshow(add_colored_mask(image, mask_image))\n",
    "axs[3, 2].set_title(\"Diff.\")\n",
    "axs[3, 2].imshow(diff_mask(mask_image, predict_image))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "fc6cc9565c3f0df279dd1a79ba91c0b61d9e29fd"
   },
   "outputs": [],
   "source": [
    "!tar zcf results.tgz --directory=../input/segmentation/test ."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
